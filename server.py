import os, time
from datetime import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS
from flask_socketio import SocketIO, emit
import requests

# ====== App & Socket ======
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})
socketio = SocketIO(app, cors_allowed_origins="*", async_mode="eventlet")

OPENAI_KEY  = os.getenv("OPENAI_API_KEY", "")
GEMINI_KEY  = os.getenv("GEMINI_API_KEY", "")
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "gemini-1.5-flash")

# ====== Helpers ======
def reply_demo(user_text: str) -> str:
    now = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
    tips = [
        "M√¨nh ƒëang ·ªü ch·∫ø ƒë·ªô DEMO (kh√¥ng c√≥ API key).",
        "B·∫°n c√≥ th·ªÉ th√™m GEMINI_API_KEY ho·∫∑c OPENAI_API_KEY v√†o Render ‚Üí Environment.",
        "Sau khi th√™m key, redeploy l√† d√πng ƒë∆∞·ª£c tr·∫£ l·ªùi AI th·∫≠t."
    ]
    return f"[DEMO] {now}. B·∫°n h·ªèi: ‚Äú{user_text}‚Äù. " + " ".join(tips)

def call_openai(model: str, text: str) -> str:
    """Minimal OpenAI Chat Completions (gpt-4o-mini / gpt-4o)"""
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {OPENAI_KEY}"}
    payload = {
        "model": model or "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω n√≥i ti·∫øng Vi·ªát, tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng."},
            {"role": "user", "content": text}
        ]
    }
    r = requests.post(url, json=payload, headers=headers, timeout=60)
    r.raise_for_status()
    data = r.json()
    return data["choices"][0]["message"]["content"]

def call_gemini(model: str, text: str) -> str:
    """Google Gemini generateContent v1beta (HTTP)"""
    use_model = model or DEFAULT_MODEL or "gemini-1.5-flash"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{use_model}:generateContent?key={GEMINI_KEY}"
    payload = {"contents": [{"parts": [{"text": text}]}]}
    r = requests.post(url, json=payload, timeout=60)
    # Gemini tr·∫£ 200 c·∫£ khi l·ªói model kh√¥ng t·ªìn t·∫°i -> ki·ªÉm tra c·∫©n th·∫≠n
    if r.status_code != 200:
        raise RuntimeError(f"Gemini HTTP {r.status_code}: {r.text[:500]}")
    data = r.json()
    try:
        return data["candidates"][0]["content"]["parts"][0]["text"]
    except Exception:
        # tr·∫£ th√¥ng b√°o d·ªÖ hi·ªÉu n·∫øu model sai t√™n
        msg = data.get("error", {}).get("message") or str(data)[:400]
        raise RuntimeError(f"Gemini response error: {msg}")

def smart_answer(model: str, text: str) -> str:
    text = (text or "").strip()
    if not text:
        return "B·∫°n h√£y nh·∫≠p n·ªôi dung c·∫ßn h·ªèi nh√©."
    # M·ªôt v√†i rule nhanh (v√≠ d·ª• th·ªùi ti·∫øt demo, gi·ªù)
    low = text.lower()
    if "m·∫•y gi·ªù" in low or "th·ªùi gian" in low:
        return time.strftime("B√¢y gi·ªù l√† %H:%M:%S (gi·ªù m√°y ch·ªß).")
    # ∆Øu ti√™n Gemini n·∫øu c√≥ key v√† model b·∫Øt ƒë·∫ßu b·∫±ng "gemini"
    if GEMINI_KEY and (model.startswith("gemini") or not OPENAI_KEY):
        return call_gemini(model, text)
    if OPENAI_KEY:
        return call_openai(model or "gpt-4o-mini", text)
    # fallback demo
    return reply_demo(text)

# ====== REST endpoints ======
@app.get("/health")
def health():
    return jsonify({"ok": True, "ts": int(time.time())})

@app.post("/ai/chat")
def ai_chat():
    data = request.get_json(silent=True) or {}
    model = (data.get("model") or DEFAULT_MODEL or "").strip()
    text  = data.get("text", "")
    try:
        out = smart_answer(model, text)
        return jsonify({"ok": True, "model": model, "answer": out})
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)[:800]}), 400

# ====== Socket.IO (2 chi·ªÅu, typing) ======
@socketio.on("connect")
def on_connect():
    emit("status", {"type": "info", "text": "WS connected üéß"}, broadcast=False)

@socketio.on("disconnect")
def on_disconnect():
    # nothing to broadcast to others on personal app
    pass

@socketio.on("typing")
def on_typing(data):
    # client g·ª≠i {typing: true/false}
    emit("typing", {"typing": bool(data.get("typing"))}, broadcast=True, include_self=False)

@socketio.on("message")
def on_message(data):
    """Client g·ª≠i {text, model}; server ph√°t l·∫°i tin user, g·ªçi AI r·ªìi ph√°t tin AI"""
    text  = (data or {}).get("text", "")
    model = (data or {}).get("model", DEFAULT_MODEL)
    # ph√°t bong b√≥ng ng∆∞·ªùi d√πng (echo)
    emit("message", {"role": "user", "text": text}, broadcast=True)
    # b√°o ƒëang g√µ
    emit("typing", {"typing": True}, broadcast=True)
    try:
        answer = smart_answer(model, text)
    except Exception as e:
        answer = f"L·ªói: {e}"
    # d·ª´ng ‚Äútyping‚Äù v√† ph√°t tr·∫£ l·ªùi
    emit("typing", {"typing": False}, broadcast=True)
    emit("message", {"role": "assistant", "text": answer}, broadcast=True)

# ====== Entry point (Render s·∫Ω ch·∫°y qua Procfile) ======
if __name__ == "__main__":
    # D√†nh cho ch·∫°y local: python server.py
    socketio.run(app, host="0.0.0.0", port=int(os.getenv("PORT", "8000")))
